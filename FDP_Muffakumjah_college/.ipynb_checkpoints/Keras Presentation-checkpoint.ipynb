{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Keras with Tensorflow Backend\n",
    "# Author: Prudhvi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"keras-tensorflow-logo.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation\n",
    "## Install Keras from PyPI (recommended):\n",
    "```sudo pip install keras```\n",
    "### If you are using a virtualenv, you may want to avoid using sudo:\n",
    "```pip install keras```\n",
    "## Alternatively: install Keras from the Github source:\n",
    "#### First, clone Keras using git:\n",
    "``` git clone https://github.com/keras-team/keras.git ```\n",
    "#### Then, cd to the Keras folder and run the install command:\n",
    "```cd keras```\n",
    "```sudo python setup.py install```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras uses frameworks like tensorflow,CNTK,Theano as backend for low level operations like tensor products, convolutions and so on.\n",
    "By default, Keras will use TensorFlow as its tensor manipulation library. To change it to CNTK or Theano we can follow these [instructions](https://keras.io/backend/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look into the guiding principles of Keras\n",
    "\n",
    "- __User friendliness.__ Keras is an API designed for human beings, not machines. It puts user experience front and center. Keras follows best practices for reducing cognitive load: it offers consistent & simple APIs, it minimizes the number of user actions required for common use cases, and it provides clear and actionable feedback upon user error.\n",
    "\n",
    "\n",
    "- __Modularity.__ A model is understood as a sequence or a graph of standalone, fully-configurable modules that can be plugged together with as little restrictions as possible. In particular, neural layers, cost functions, optimizers, initialization schemes, activation functions, regularization schemes are all standalone modules that you can combine to create new models.\n",
    "\n",
    "\n",
    "- __Easy extensibility.__ New modules are simple to add (as new classes and functions), and existing modules provide ample examples. To be able to easily create new modules allows for total expressiveness, making Keras suitable for advanced research.\n",
    "\n",
    "\n",
    "- __Work with Python__. No separate models configuration files in a declarative format. Models are described in Python code, which is compact, easier to debug, and allows for ease of extensibility.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's look into keras with an example \n",
    "##### (MNIST digits classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling Keras layers on TensorFlow tensors \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Exploration:\n",
    "MNIST is a database of handwritten digits (1 to 10)\n",
    "\n",
    "training set: 60,000 examples.\n",
    "\n",
    "test set: 10,000 examples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning).\n",
    "2 seconds per epoch on a K520 GPU.\n",
    "'''\n",
    "# Importing all the required packages and dataset\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# loading the data\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "#  Each sample image is 28x28 and linearized as a vector of size 1x784.\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "# coverting to float so as to accomodate the normalized values lying between 0 to 1\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "# Normalizing the data\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while explaining simply to show\n",
    "# next step is to change the vectors into categorical that is one hot encoding\n",
    "# print(y_train)\n",
    "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__What is a Sequential model in keras?__\n",
    "\n",
    "__`model = Sequential()`__\n",
    "\n",
    "The Sequential model is a linear stack of layers. We can create a Sequential model by passing a list of layer instances to the constructor like the type of the layer and the properties of the layer like the activation as mentioned below.\n",
    "\n",
    "Adding a layer is done by:\n",
    "\n",
    "__`model.add()`__\n",
    "\n",
    "Passing the instances to the constructor:\n",
    "\n",
    "__`model.add(Dense(512, activation='relu', input_shape=(784,)))`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Before building the model lets explore the [layers](https://keras.io/layers/core/) and calculate the math__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model layers and architecture \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![model architecture](model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model details\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training a model, we need to configure the learning process, which is done via the compile method. \n",
    "\n",
    "__An optimizer.__ \n",
    "\n",
    "This could be the string identifier of an existing optimizer (such as rmsprop or adagrad), or an instance of the Optimizer class. See: optimizers.\n",
    "\n",
    "__A loss function.__ \n",
    "\n",
    "This is the objective that the model will try to minimize. It can be the string identifier of an existing loss function (such as categorical_crossentropy or mse), or it can be an objective function. See: losses.\n",
    "\n",
    "__A list of metrics.__ \n",
    "\n",
    "For any classification problem you will want to set this to metrics=['accuracy']. A metric could be the string identifier of an existing metric or a custom metric function.\n",
    "\n",
    "__Ex:__\n",
    "\n",
    "__`model.compile(loss,optimizer,metrics)`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s - loss: 0.2482 - acc: 0.9241 - val_loss: 0.1231 - val_acc: 0.9625\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 4s - loss: 0.1003 - acc: 0.9694 - val_loss: 0.0778 - val_acc: 0.9763\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s - loss: 0.0767 - acc: 0.9764 - val_loss: 0.0741 - val_acc: 0.9782\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s - loss: 0.0613 - acc: 0.9819 - val_loss: 0.0762 - val_acc: 0.9796\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 4s - loss: 0.0513 - acc: 0.9846 - val_loss: 0.0863 - val_acc: 0.9772\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 4s - loss: 0.0452 - acc: 0.9868 - val_loss: 0.0908 - val_acc: 0.9784\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 4s - loss: 0.0415 - acc: 0.9875 - val_loss: 0.0843 - val_acc: 0.9806\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s - loss: 0.0361 - acc: 0.9891 - val_loss: 0.0791 - val_acc: 0.9816\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s - loss: 0.0346 - acc: 0.9906 - val_loss: 0.0818 - val_acc: 0.9822\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s - loss: 0.0291 - acc: 0.9916 - val_loss: 0.0815 - val_acc: 0.9838\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s - loss: 0.0283 - acc: 0.9922 - val_loss: 0.1120 - val_acc: 0.9803\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s - loss: 0.0272 - acc: 0.9925 - val_loss: 0.0926 - val_acc: 0.9816\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 5s - loss: 0.0238 - acc: 0.9933 - val_loss: 0.1074 - val_acc: 0.9809\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s - loss: 0.0220 - acc: 0.9940 - val_loss: 0.1042 - val_acc: 0.9827\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s - loss: 0.0230 - acc: 0.9938 - val_loss: 0.1117 - val_acc: 0.9821\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s - loss: 0.0236 - acc: 0.9939 - val_loss: 0.1077 - val_acc: 0.9836\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 5s - loss: 0.0241 - acc: 0.9941 - val_loss: 0.0982 - val_acc: 0.9837\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s - loss: 0.0194 - acc: 0.9948 - val_loss: 0.1142 - val_acc: 0.9829\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 5s - loss: 0.0201 - acc: 0.9950 - val_loss: 0.1124 - val_acc: 0.9829\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 5s - loss: 0.0192 - acc: 0.9949 - val_loss: 0.1271 - val_acc: 0.9801\n",
      "Test loss: 0.127105176715\n",
      "Test accuracy: 0.9801\n"
     ]
    }
   ],
   "source": [
    "# configuring the model is done by compile\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#For training a model, we use the  fit function.\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
